import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from sklearn.utils.class_weight import compute_class_weight
import numpy as np
import os

# ğŸ“ ê²½ë¡œ ì„¤ì •
DATA_DIR = 'data/personal_color'
SAVE_DIR = 'saved_models'
os.makedirs(SAVE_DIR, exist_ok=True)

# ğŸ”§ ë°ì´í„° ì¦ê°• ë° ì „ì²˜ë¦¬ (ì ì ˆí•œ ìˆ˜ì¤€ìœ¼ë¡œ ì™„í™”)
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
    rotation_range=15,
    brightness_range=[0.8, 1.2],
    width_shift_range=0.05,
    height_shift_range=0.05
)

# âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train_data = train_datagen.flow_from_directory(
    DATA_DIR,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    shuffle=True,
    seed=42
)

val_data = train_datagen.flow_from_directory(
    DATA_DIR,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

# âœ… í´ë˜ìŠ¤ ì´ë¦„ ì €ì¥
class_names = [k.replace('\\', '_') for k in train_data.class_indices.keys()]
with open(os.path.join(SAVE_DIR, "class_names.txt"), "w") as f:
    for name in class_names:
        f.write(name + "\n")
print(f"ğŸ“ í´ë˜ìŠ¤ ëª©ë¡ ì €ì¥ ì™„ë£Œ: {class_names}")

# âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
labels = train_data.classes
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(labels),
    y=labels
)
class_weights = dict(enumerate(class_weights))
print("âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:", class_weights)

# âœ… EfficientNetB0 ê¸°ë°˜ ëª¨ë¸ êµ¬ì„±
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = GlobalAveragePooling2D()(base_model.output)
x = Dropout(0.3)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.3)(x)
x = Dense(128, activation='relu')(x)
output = Dense(len(class_names), activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

# ğŸ”§ fine-tuning: ë§ˆì§€ë§‰ 30ê°œ ë ˆì´ì–´ë§Œ í•™ìŠµ
for layer in base_model.layers[:-30]:
    layer.trainable = False
for layer in base_model.layers[-30:]:
    layer.trainable = True

# âœ… ì»´íŒŒì¼
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# âœ… ì½œë°± ì„¤ì •
checkpoint = ModelCheckpoint(
    os.path.join(SAVE_DIR, 'best_model.h5'),
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)
early_stop = EarlyStopping(
    monitor='val_accuracy',
    patience=10,
    restore_best_weights=True,
    verbose=1
)

# âœ… í•™ìŠµ
history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=100,
    class_weight=class_weights,
    callbacks=[checkpoint, early_stop]
)

# âœ… ëª¨ë¸ ì €ì¥
model.save(os.path.join(SAVE_DIR, 'personal_color_model.h5'))
print("âœ… ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ")
